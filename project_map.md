# Project Map — Uni-Sign

- **Root:** `/home/danielharding/projects/dev/Uni-Sign`
- **Generated:** 2025-08-22 15:09:58
- **Max depth:** 4, **Max previews:** 80
- **Previewed extensions:** .csv, .json, .md, .txt, .py

## Directory Tree (depth ≤ 4)

- **.** — 115 files, 2.6 GB
  - .DS_Store (8.0 KB)
  - .gitignore (148 B)
  - config.py (1.3 KB)
  - datasets.py (24.1 KB)
  - deformable_attention_2d.py (10.4 KB)
  - fine_tuning.py (13.2 KB)
  - models.py (14.8 KB)
  - pre_training.py (10.5 KB)
  - **checkpoints** — 1 files, 480 B
    - **checkpoints/wlbs_stage2_words** — 1 files, 480 B
      - train.log (480 B)
  - **data** — 27 files, 400.7 MB
    - .DS_Store (6.0 KB)
    - **data/CSL_Daily** — 4 files, 608.1 KB
      - .DS_Store (6.0 KB)
      - labels.dev (50.3 KB)
      - labels.test (52.2 KB)
      - labels.train (499.6 KB)
    - **data/CSL_News** — 16 files, 397.3 MB
      - .DS_Store (6.0 KB)
      - CSL_News_Labels.csv (109.2 MB)
      - CSL_News_Labels.filtered.skip_pose.json (137.9 MB)
      - CSL_News_Labels.json (137.9 MB)
      - **data/CSL_News/pose_format** — 2 files, 2.7 KB
        - check_missing_pose_from_csv.py (2.7 KB)
        - pose_format (?)
      - **data/CSL_News/rgb_format** — 10 files, 12.3 MB
        -     --mode lightweight \ (1.1 MB)
        - )) (1.8 MB)
        - 000000000785.jpg") (990.8 KB)
        - all_modules() (1.6 MB)
        - checkpoints work (1.1 MB)
        - for z in *.zip; do (2.1 MB)
        - pose_format" (425.6 KB)
        - pose_full official_mmpose mmpose.broken-* (1.1 MB)
        - **data/CSL_News/rgb_format/archive_001** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_341** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_342** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_343** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_344** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_345** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_346** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_347** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_348** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_349** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_350** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_351** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_352** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_353** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_354** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_355** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_356** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_357** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_358** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_359** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_360** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_361** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_362** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_363** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_364** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_365** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_366** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_367** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_368** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_369** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_370** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_371** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_372** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_373** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_374** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_375** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_376** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_377** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_378** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_379** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_380** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_381** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_382** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_383** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_384** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_385** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_386** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_387** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_388** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_389** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_390** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_391** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_392** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_393** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_394** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_395** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_396** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_397** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_398** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_399** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_400** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_401** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_402** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_403** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_404** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_405** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_406** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_407** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_408** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_409** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_410** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_411** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_412** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_413** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_414** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_415** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_416** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_417** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_418** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_419** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_420** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_421** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_422** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_423** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_424** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_425** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_426** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_427** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_428** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_429** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_430** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_431** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_432** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_433** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_434** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_435** — 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_436** — 0 files, 0 B
        - **data/CSL_News/rgb_format/rgb_format** — 0 files, 0 B
    - **data/WLBSL** — 6 files, 2.8 MB
      - bsl-text.txt (9 B)
      - labels.dev (72.4 KB)
      - labels.test (72.7 KB)
      - labels.train (579.7 KB)
      - WLBSL_Labels.csv (1.4 MB)
      - WLBSL_Labels.json (771.2 KB)
      - **data/WLBSL/pose_format** — 0 files, 0 B
      - **data/WLBSL/rgb_format** — 0 files, 0 B
  - **dataset** — 27 files, 400.7 MB
    - .DS_Store (6.0 KB)
    - **dataset/CSL_Daily** — 4 files, 608.1 KB
      - .DS_Store (6.0 KB)
      - labels.dev (50.3 KB)
      - labels.test (52.2 KB)
      - labels.train (499.6 KB)
    - **dataset/CSL_News** — 16 files, 397.3 MB
      - .DS_Store (6.0 KB)
      - CSL_News_Labels.csv (109.2 MB)
      - CSL_News_Labels.filtered.skip_pose.json (137.9 MB)
      - CSL_News_Labels.json (137.9 MB)
      - **dataset/CSL_News/pose_format** — 2 files, 2.7 KB
        - check_missing_pose_from_csv.py (2.7 KB)
        - pose_format (?)
    - **dataset/WLBSL** — 6 files, 2.8 MB
      - bsl-text.txt (9 B)
      - labels.dev (72.4 KB)
      - labels.test (72.7 KB)
      - labels.train (579.7 KB)
      - WLBSL_Labels.csv (1.4 MB)
      - WLBSL_Labels.json (771.2 KB)
      - **dataset/WLBSL/pose_format** — 0 files, 0 B
      - **dataset/WLBSL/rgb_format** — 0 files, 0 B
  - **demo** — 47 files, 264.6 KB
    - online_inference.py (4.5 KB)
    - pose_extraction.py (3.0 KB)
    - README.md (1.4 KB)
    - **demo/rtmlib-main** — 44 files, 255.7 KB
      - .gitignore (1.3 KB)
      - .pre-commit-config.yaml (1.3 KB)
      - body_with_feet_demo.py (1.3 KB)
      - demo.jpg (75.3 KB)
      - hand_demo.py (1.2 KB)
      - LICENSE (11.1 KB)
      - README.md (16.4 KB)
      - requirements.txt (58 B)
      - **demo/rtmlib-main/rtmlib** — 32 files, 138.6 KB
        - __init__.py (345 B)
        - version.py (931 B)
        - **demo/rtmlib-main/rtmlib/tools** — 21 files, 68.9 KB
          - __init__.py (296 B)
          - base.py (4.5 KB)
          - file.py (5.8 KB)
        - **demo/rtmlib-main/rtmlib/visualization** — 9 files, 68.4 KB
          - __init__.py (246 B)
          - draw.py (6.5 KB)
  - **docs** — 2 files, 567.7 KB
    - DATASET.md (2.3 KB)
    - framework.png (565.4 KB)
  - **download_scripts** — 1 files, 3.6 KB
    - download_CSL_News.py (3.6 KB)
  - **external_metrics** — 5 files, 135.9 KB
    - .DS_Store (6.0 KB)
    - __init__.py (0 B)
    - mscoco_rouge.py (2.2 KB)
    - Rouge.py (10.5 KB)
    - sacrebleu.py (117.2 KB)
  - **out** — 2 files, 8.6 KB
    - **out/stage1_pretraining** — 1 files, 6.0 KB
      - log.txt (6.0 KB)
    - **out/wlbs_stage2_islr** — 1 files, 2.6 KB
      - train.log (2.6 KB)
  - **pretrained_weight** — 6 files, 2.2 GB
    - **pretrained_weight/mt5-base** — 6 files, 2.2 GB
      - config.json (827 B)
      - generation_config.json (142 B)
      - model.safetensors (2.2 GB)
      - special_tokens_map.json (416 B)
      - spiece.model (4.1 MB)
      - tokenizer_config.json (862 B)
  - **script** — 6 files, 4.8 KB
    - eval_stage3.sh (709 B)
    - run_stage1.sh (707 B)
    - train_stage1-advanced.sh (1.6 KB)
    - train_stage1.sh (294 B)
    - train_stage2.sh (392 B)
    - train_stage3.sh (1.2 KB)
  - **stgcn_layers** — 4 files, 15.6 KB
    - .DS_Store (6.0 KB)
    - __init__.py (69 B)
    - gcn_utils.py (6.0 KB)
    - stgcn_block.py (3.6 KB)
  - **tools** — 1 files, 9.7 KB
    - project_map.py (9.7 KB)

## File Previews

### `README.md` (5.4 KB)
```text
<h3 align="center"><a href="" style="color:#9C276A">
Uni-Sign: Toward Unified Sign Language Understanding at Scale</a></h3>
<h5 align="center"> 
If our project helps you, please give us a star🌟 on GitHub, that would motivate us a lot!
</h2>
```

### `SLRT_metrics.py` (10.6 KB)
```text
# coding: utf-8
"""
This module holds various MT evaluation metrics.
"""

```

### `config.py` (1.3 KB)
```text
mt5_path = "./pretrained_weight/mt5-base"

# label paths
train_label_paths = {
    "CSL_News": "./data/CSL_News/CSL_News_Labels.json",
```

### `datasets.py` (24.1 KB)
```text
import torch
import utils as utils
import torch.utils.data.dataset as Dataset
from torch.nn.utils.rnn import pad_sequence
from PIL import Image
```

### `deformable_attention_2d.py` (10.4 KB)
```text
# Clone from https://github.com/lucidrains/deformable-attention
import torch
import torch.nn.functional as F
from torch import nn, einsum

```

### `fine_tuning.py` (13.2 KB)
```text
import torch
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import DataLoader
from models import Uni_Sign
import utils as utils
```

### `models.py` (14.8 KB)
```text
from torch import Tensor
import torch
from torch import nn
import torch.utils.checkpoint
import contextlib
```

### `pre_training.py` (10.5 KB)
```text

from pickletools import optimize
import torch
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import DataLoader
```

### `requirements.txt` (446 B)
```text
accelerate==0.29.2
decord==0.6.0
deepspeed==0.16.3
einops==0.6.1
matplotlib==3.4.3
```

### `sitecustomize.py` (252 B)
```text
# Shim to load pickles produced under NumPy 2.x while running NumPy 1.x
import sys, types, numpy as _np
if 'numpy._core' not in sys.modules:
    m = types.ModuleType('numpy._core')
    m.__dict__.update(_np.__dict__)
```

### `utils.py` (21.0 KB)
```text
"""
This file is modified from:
https://github.com/facebookresearch/deit/blob/main/utils.py
"""

```

### `pretrained_weight/mt5-base/config.json` (827 B)
```json
{
  "_name_or_path": "google/mt5-base",
  "architectures": [
    "MT5ForConditionalGeneration"
  ],
```

### `pretrained_weight/mt5-base/generation_config.json` (142 B)
```json
{
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
```

### `pretrained_weight/mt5-base/special_tokens_map.json` (416 B)
```json
{
  "eos_token": {
    "content": "</s>",
    "lstrip": false,
    "normalized": false,
```

### `pretrained_weight/mt5-base/tokenizer_config.json` (862 B)
```json
{
  "add_prefix_space": true,
  "added_tokens_decoder": {
    "0": {
      "content": "<pad>",
```

### `external_metrics/Rouge.py` (10.5 KB)
```text
"""ROUGE metric implementation.
Copy from tf_seq2seq/seq2seq/metrics/rouge.py.
This is a modified and slightly extended verison of
https://github.com/miso-belica/sumy/blob/dev/sumy/evaluation/rouge.py.
"""
```

### `external_metrics/__init__.py` (0 B)
```text
[empty]
```

### `external_metrics/mscoco_rouge.py` (2.2 KB)
```text
#!/usr/bin/env python
#
# File Name : mscoco_rouge.py
#
# Description : Computes ROUGE-L metric as described by Lin and Hovey (2004)
```

### `external_metrics/sacrebleu.py` (117.2 KB)
```text
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Copyright 2017--2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
```

### `docs/DATASET.md` (2.3 KB)
```text
### Dataset structure
For simplicity, our datasets are structured in the following way:
```
/Uni-Sign/dataset/
├── CSL_News
```

### `data/WLBSL/WLBSL_Labels.csv` (1.4 MB)
```csv
video_path,pose_path,label
/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/rgb_format/abandon_001.mp4,/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/pose_format/abandon_001.pkl,abandon
/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/rgb_format/abashed_001.mp4,/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/pose_format/abashed_001.pkl,abashed
/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/rgb_format/abattoir_001.mp4,/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/pose_format/abattoir_001.pkl,abattoir
/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/rgb_format/abbreviate_001.mp4,/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/pose_format/abbreviate_001.pkl,abbreviate
```

### `data/WLBSL/WLBSL_Labels.json` (771.2 KB)
```json
[
  {
    "video": "abandon_001.mp4",
    "pose": "abandon_001.pkl",
    "text": "abandon"
```

### `data/WLBSL/bsl-text.txt` (9 B)
```text
Text BSL
```

### `data/CSL_News/CSL_News_Labels.csv` (109.2 MB)
```csv
video,pose,text
Common-Concerns_20201113_0-287_14330.mp4,Common-Concerns_20201113_0-287_14330.pkl,欢迎收看新闻频道，每天十八点为您直播的共同关注浦东开发开放三十周年庆祝大会十二号上午在上海市举行。
Common-Concerns_20201113_1562-2012_239580.mp4,Common-Concerns_20201113_1562-2012_239580.pkl,九时三十分，大会开始，干妈全体起立。
Common-Concerns_20201113_3237-3612_141834.mp4,Common-Concerns_20201113_3237-3612_141834.pkl,他强调，三十年前，党中央全面研判国际国内大事，统筹把握改革发展大局，作出了开发开放。
Common-Concerns_20201113_3562-3812_377955.mp4,Common-Concerns_20201113_3562-3812_377955.pkl,上海浦东的重大决策，掀开了我国改革开放向纵深推进的崭新篇章。
```

### `data/CSL_News/CSL_News_Labels.filtered.skip_pose.json` (137.9 MB)
```json
[
  {
    "video": "Common-Concerns_20201113_0-287_14330.mp4",
    "pose": "Common-Concerns_20201113_0-287_14330.pkl",
    "text": "欢迎收看新闻频道，每天十八点为您直播的共同关注浦东开发开放三十周年庆祝大会十二号上午在上海市举行。"
```

### `data/CSL_News/CSL_News_Labels.json` (137.9 MB)
```json
[
  {
    "video": "Common-Concerns_20201113_0-287_14330.mp4",
    "pose": "Common-Concerns_20201113_0-287_14330.pkl",
    "text": "欢迎收看新闻频道，每天十八点为您直播的共同关注浦东开发开放三十周年庆祝大会十二号上午在上海市举行。"
```

### `data/CSL_News/pose_format/check_missing_pose_from_csv.py` (2.7 KB)
```text
#!/usr/bin/env python3
import csv
from pathlib import Path

# --- paths ---
```

### `demo/README.md` (1.4 KB)
```text
## ⚠️ Warning
Due to a busy schedule lately😢, the following demo has not been verified yet.  I wrote it quickly based on logical reasoning to hopefully cover the common needs of many developers/researchers🧑‍🎓. I will check it as soon as possible. If you encounter any problems, feel free to open an issue.

## 🛠️ Installation
We need to install some package to launch the files in here.
```

### `demo/online_inference.py` (4.5 KB)
```text
import torch
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import DataLoader
from models import Uni_Sign
import utils as utils
```

### `demo/pose_extraction.py` (3.0 KB)
```text
import argparse
import os
import cv2
import glob
import pickle
```

### `demo/rtmlib-main/README.md` (16.4 KB)
```text
# rtmlib

![demo](https://github.com/Tau-J/rtmlib/assets/13503330/b7e8ce8b-3134-43cf-bba6-d81656897289)

rtmlib is a super lightweight library to conduct pose estimation based on [RTMPose](https://github.com/open-mmlab/mmpose/tree/dev-1.x/projects/rtmpose) models **WITHOUT** any dependencies like mmcv, mmpose, mmdet, etc.
```

### `demo/rtmlib-main/body_with_feet_demo.py` (1.3 KB)
```text
import time
import cv2
from rtmlib import BodyWithFeet, PoseTracker, draw_skeleton

device = 'cpu'
```

### `demo/rtmlib-main/hand_demo.py` (1.2 KB)
```text
import time

import cv2

from rtmlib import Hand, PoseTracker, draw_skeleton
```

### `demo/rtmlib-main/requirements.txt` (58 B)
```text
numpy
onnxruntime
opencv-contrib-python
opencv-python
tqdm
```

### `demo/rtmlib-main/rtmo_demo.py` (1.2 KB)
```text
import time

import cv2

from rtmlib import Body, draw_skeleton
```

### `demo/rtmlib-main/setup.py` (4.2 KB)
```text
from setuptools import find_packages, setup


def readme():
    with open('README.md', encoding='utf-8') as f:
```

### `demo/rtmlib-main/webui.py` (2.6 KB)
```text
import gradio as gr
import numpy as np

from rtmlib import Body, Wholebody, draw_skeleton

```

### `demo/rtmlib-main/wholebody_demo.py` (1.2 KB)
```text
import time

import cv2

from rtmlib import PoseTracker, Wholebody, draw_skeleton
```

### `demo/rtmlib-main/rtmlib/__init__.py` (345 B)
```text
from .tools import (RTMO, YOLOX, Body, Hand, PoseTracker, RTMDet, RTMPose,
                    Wholebody, BodyWithFeet, Custom)
from .visualization.draw import draw_bbox, draw_skeleton

__all__ = [
```

### `demo/rtmlib-main/rtmlib/version.py` (931 B)
```text
__version__ = '0.0.13'
short_version = __version__


def parse_version_info(version_str):
```

### `demo/rtmlib-main/rtmlib/visualization/__init__.py` (246 B)
```text
from .draw import draw_bbox, draw_skeleton
from .skeleton import coco17, coco133, hand21, openpose18, openpose134, halpe26

__all__ = [
    'draw_skeleton', 'draw_bbox', 'coco17', 'coco133', 'hand21', 'openpose18',
```

### `demo/rtmlib-main/rtmlib/visualization/draw.py` (6.5 KB)
```text
import math

import cv2
import numpy as np

```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/__init__.py` (267 B)
```text
from .coco17 import coco17
from .coco133 import coco133
from .hand21 import hand21
from .openpose18 import openpose18
from .openpose134 import openpose134
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/coco133.py` (21.6 KB)
```text
coco133 = dict(
    name='coco133',
    keypoint_info={
        0:
        dict(name='nose', id=0, color=[51, 153, 255], swap=''),
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/coco17.py` (5.9 KB)
```text
coco17 = dict(name='coco17',
              keypoint_info={
                  0:
                  dict(name='nose', id=0, color=[51, 153, 255], swap=''),
                  1:
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/halpe26.py` (4.6 KB)
```text
halpe26 = dict(name='halpe26',         
    keypoint_info={
        0: dict(name='nose', id=0, color=[51, 153, 255], type='upper', swap=''),
        1: dict(name='left_eye', id=1, color=[51, 153, 255], type='upper', swap='right_eye'),
        2: dict(name='right_eye', id=2, color=[51, 153, 255], type='upper', swap='left_eye'),
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/hand21.py` (6.0 KB)
```text
hand21 = dict(dataset_name='hand21',
              keypoint_info={
                  0:
                  dict(name='wrist', id=0, color=[255, 255, 255], swap=''),
                  1:
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/openpose134.py` (20.3 KB)
```text
openpose134 = dict(
    name='openpose134',
    keypoint_info={
        0:
        dict(name='nose', id=0, color=[255, 0, 0], swap=''),
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/openpose18.py` (3.1 KB)
```text
openpose18 = dict(
    name='openpose18',
    keypoint_info={
        0:
        dict(name='nose', id=0, color=[255, 0, 0], swap=''),
```

### `demo/rtmlib-main/rtmlib/tools/__init__.py` (296 B)
```text
from .object_detection import YOLOX, RTMDet
from .pose_estimation import RTMO, RTMPose
from .solution import Body, Hand, PoseTracker, Wholebody, BodyWithFeet, Custom

__all__ = [
```

### `demo/rtmlib-main/rtmlib/tools/base.py` (4.5 KB)
```text
import os
from abc import ABCMeta, abstractmethod
from typing import Any

import cv2
```

### `demo/rtmlib-main/rtmlib/tools/file.py` (5.8 KB)
```text
import hashlib
import os
import re
import sys
import tempfile
```

### `demo/rtmlib-main/rtmlib/tools/pose_estimation/__init__.py` (83 B)
```text
from .rtmo import RTMO
from .rtmpose import RTMPose

__all__ = ['RTMPose', 'RTMO']
```

### `demo/rtmlib-main/rtmlib/tools/pose_estimation/post_processings.py` (2.2 KB)
```text
from typing import Tuple

import numpy as np


```

### `demo/rtmlib-main/rtmlib/tools/pose_estimation/pre_processings.py` (5.3 KB)
```text
from typing import Tuple

import cv2
import numpy as np

```

### `demo/rtmlib-main/rtmlib/tools/pose_estimation/rtmo.py` (4.0 KB)
```text
from typing import List, Tuple

import cv2
import numpy as np

```

### `demo/rtmlib-main/rtmlib/tools/pose_estimation/rtmpose.py` (3.5 KB)
```text
from typing import List, Tuple

import numpy as np

from ..base import BaseTool
```

### `demo/rtmlib-main/rtmlib/tools/solution/__init__.py` (267 B)
```text
from .body import Body
from .hand import Hand
from .pose_tracker import PoseTracker
from .wholebody import Wholebody
from .body_with_feet import BodyWithFeet
```

### `demo/rtmlib-main/rtmlib/tools/solution/body.py` (5.0 KB)
```text
'''
Example:

import cv2

```

### `demo/rtmlib-main/rtmlib/tools/solution/body_with_feet.py` (4.9 KB)
```text
'''
Example:

import cv2
from rtmlib import BodyWithFeet, draw_skeleton
```

### `demo/rtmlib-main/rtmlib/tools/solution/custom.py` (4.2 KB)
```text
'''
Example:

import cv2

```

### `demo/rtmlib-main/rtmlib/tools/solution/hand.py` (2.8 KB)
```text
'''
Example:

import cv2

```

### `demo/rtmlib-main/rtmlib/tools/solution/pose_tracker.py` (8.3 KB)
```text
'''
Example:

import cv2
from functools import partial
```

### `demo/rtmlib-main/rtmlib/tools/solution/wholebody.py` (5.2 KB)
```text
'''
Example:

import cv2

```

### `demo/rtmlib-main/rtmlib/tools/solution/utils/__init__.py` (0 B)
```text
[empty]
```

### `demo/rtmlib-main/rtmlib/tools/solution/utils/types.py` (832 B)
```text
# poted from controlnet repo
from typing import List, NamedTuple, Optional


class Keypoint(NamedTuple):
```

### `demo/rtmlib-main/rtmlib/tools/object_detection/__init__.py` (83 B)
```text
from .rtmdet import RTMDet
from .yolox import YOLOX

__all__ = ['RTMDet', 'YOLOX']
```

### `demo/rtmlib-main/rtmlib/tools/object_detection/post_processings.py` (1.7 KB)
```text
import numpy as np


def nms(boxes, scores, nms_thr):
    """Single class NMS implemented in Numpy."""
```

### `demo/rtmlib-main/rtmlib/tools/object_detection/rtmdet.py` (5.0 KB)
```text
from typing import List, Tuple

import cv2
import numpy as np

```

### `demo/rtmlib-main/rtmlib/tools/object_detection/yolox.py` (5.1 KB)
```text
# Code modified from https://github.com/IDEA-Research/DWPose/blob/opencv_onnx/ControlNet-v1-1-nightly/annotator/dwpose/cv_ox_det.py  # noqa
from typing import List, Tuple

import cv2
import numpy as np
```

### `download_scripts/download_CSL_News.py` (3.6 KB)
```text
# Modified from https://github.com/NJU-PCALab/OpenVid-1M/blob/main/download_scripts/download_OpenVid.py
import os
import subprocess
import argparse

```

### `stgcn_layers/__init__.py` (69 B)
```text
from .gcn_utils import Graph
from .stgcn_block import get_stgcn_chain
```

### `stgcn_layers/gcn_utils.py` (6.0 KB)
```text
import torch
import numpy as np
import torch.nn as nn
import pdb
import math
```

### `stgcn_layers/stgcn_block.py` (3.6 KB)
```text
import torch
import numpy as np
import torch.nn as nn
import pdb
import math
```

### `out/stage1_pretraining/log.txt` (6.0 KB)
```text
{"train_lr": 0.0002993845253182493, "train_loss": 6.785563349599164, "test_loss": 6.148706896551724, "test_bleu1": 12.901555797999029, "test_bleu2": 4.185654343580335, "test_bleu3": 2.0230725999626284, "test_bleu4": 1.1853986319842782, "test_rouge": 13.982612774881856, "epoch": 0, "n_parameters": 58 …
{"train_lr": 0.00029570729902265216, "train_loss": 6.21276195974207, "test_loss": 5.941271551724138, "test_bleu1": 13.526152319681527, "test_bleu2": 5.908415828256948, "test_bleu3": 3.4084221972124893, "test_bleu4": 2.274847922989226, "test_rouge": 16.068896434631228, "epoch": 1, "n_parameters": 587 …
{"train_lr": 0.0002884421092059307, "train_loss": 5.917739557917974, "test_loss": 5.65625, "test_bleu1": 22.601668709206542, "test_bleu2": 13.439656594920029, "test_bleu3": 9.232919972286917, "test_bleu4": 6.85038049385354, "test_rouge": 24.108112826705288, "epoch": 2, "n_parameters": 587.747368}
{"train_lr": 0.0002777678572453519, "train_loss": 5.62723655164401, "test_loss": 5.470007183908046, "test_bleu1": 28.4917077510087, "test_bleu2": 18.633522713297126, "test_bleu3": 13.529257476156124, "test_bleu4": 10.40373223447342, "test_rouge": 30.017459700072017, "epoch": 3, "n_parameters": 587.7 …
{"train_lr": 0.0002639473908269818, "train_loss": 5.442820887068665, "test_loss": 5.3652119252873565, "test_bleu1": 33.460075198406464, "test_bleu2": 22.94460240989155, "test_bleu3": 17.180685393240275, "test_bleu4": 13.498644155085653, "test_rouge": 33.54330188021793, "epoch": 4, "n_parameters": 58 …
```

### `tools/project_map.py` (9.7 KB)
```text
#!/usr/bin/env python3
"""
Project File System Map + Safe Previews

- Prints a directory tree (bounded depth and entries).
```
