# Project Map ‚Äî Uni-Sign

- **Root:** `/home/danielharding/projects/dev/Uni-Sign`
- **Generated:** 2025-08-22 15:09:58
- **Max depth:** 4, **Max previews:** 80
- **Previewed extensions:** .csv, .json, .md, .txt, .py

## Directory Tree (depth ‚â§ 4)

- **.** ‚Äî 115 files, 2.6 GB
  - .DS_Store (8.0 KB)
  - .gitignore (148 B)
  - config.py (1.3 KB)
  - datasets.py (24.1 KB)
  - deformable_attention_2d.py (10.4 KB)
  - fine_tuning.py (13.2 KB)
  - models.py (14.8 KB)
  - pre_training.py (10.5 KB)
  - **checkpoints** ‚Äî 1 files, 480 B
    - **checkpoints/wlbs_stage2_words** ‚Äî 1 files, 480 B
      - train.log (480 B)
  - **data** ‚Äî 27 files, 400.7 MB
    - .DS_Store (6.0 KB)
    - **data/CSL_Daily** ‚Äî 4 files, 608.1 KB
      - .DS_Store (6.0 KB)
      - labels.dev (50.3 KB)
      - labels.test (52.2 KB)
      - labels.train (499.6 KB)
    - **data/CSL_News** ‚Äî 16 files, 397.3 MB
      - .DS_Store (6.0 KB)
      - CSL_News_Labels.csv (109.2 MB)
      - CSL_News_Labels.filtered.skip_pose.json (137.9 MB)
      - CSL_News_Labels.json (137.9 MB)
      - **data/CSL_News/pose_format** ‚Äî 2 files, 2.7 KB
        - check_missing_pose_from_csv.py (2.7 KB)
        - pose_format (?)
      - **data/CSL_News/rgb_format** ‚Äî 10 files, 12.3 MB
        -     --mode lightweight \ (1.1 MB)
        - )) (1.8 MB)
        - 000000000785.jpg") (990.8 KB)
        - all_modules() (1.6 MB)
        - checkpoints work (1.1 MB)
        - for z in *.zip; do (2.1 MB)
        - pose_format" (425.6 KB)
        - pose_full official_mmpose mmpose.broken-* (1.1 MB)
        - **data/CSL_News/rgb_format/archive_001** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_341** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_342** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_343** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_344** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_345** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_346** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_347** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_348** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_349** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_350** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_351** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_352** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_353** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_354** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_355** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_356** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_357** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_358** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_359** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_360** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_361** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_362** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_363** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_364** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_365** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_366** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_367** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_368** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_369** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_370** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_371** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_372** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_373** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_374** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_375** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_376** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_377** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_378** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_379** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_380** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_381** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_382** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_383** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_384** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_385** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_386** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_387** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_388** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_389** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_390** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_391** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_392** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_393** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_394** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_395** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_396** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_397** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_398** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_399** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_400** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_401** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_402** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_403** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_404** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_405** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_406** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_407** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_408** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_409** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_410** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_411** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_412** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_413** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_414** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_415** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_416** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_417** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_418** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_419** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_420** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_421** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_422** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_423** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_424** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_425** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_426** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_427** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_428** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_429** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_430** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_431** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_432** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_433** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_434** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_435** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/archive_436** ‚Äî 0 files, 0 B
        - **data/CSL_News/rgb_format/rgb_format** ‚Äî 0 files, 0 B
    - **data/WLBSL** ‚Äî 6 files, 2.8 MB
      - bsl-text.txt (9 B)
      - labels.dev (72.4 KB)
      - labels.test (72.7 KB)
      - labels.train (579.7 KB)
      - WLBSL_Labels.csv (1.4 MB)
      - WLBSL_Labels.json (771.2 KB)
      - **data/WLBSL/pose_format** ‚Äî 0 files, 0 B
      - **data/WLBSL/rgb_format** ‚Äî 0 files, 0 B
  - **dataset** ‚Äî 27 files, 400.7 MB
    - .DS_Store (6.0 KB)
    - **dataset/CSL_Daily** ‚Äî 4 files, 608.1 KB
      - .DS_Store (6.0 KB)
      - labels.dev (50.3 KB)
      - labels.test (52.2 KB)
      - labels.train (499.6 KB)
    - **dataset/CSL_News** ‚Äî 16 files, 397.3 MB
      - .DS_Store (6.0 KB)
      - CSL_News_Labels.csv (109.2 MB)
      - CSL_News_Labels.filtered.skip_pose.json (137.9 MB)
      - CSL_News_Labels.json (137.9 MB)
      - **dataset/CSL_News/pose_format** ‚Äî 2 files, 2.7 KB
        - check_missing_pose_from_csv.py (2.7 KB)
        - pose_format (?)
    - **dataset/WLBSL** ‚Äî 6 files, 2.8 MB
      - bsl-text.txt (9 B)
      - labels.dev (72.4 KB)
      - labels.test (72.7 KB)
      - labels.train (579.7 KB)
      - WLBSL_Labels.csv (1.4 MB)
      - WLBSL_Labels.json (771.2 KB)
      - **dataset/WLBSL/pose_format** ‚Äî 0 files, 0 B
      - **dataset/WLBSL/rgb_format** ‚Äî 0 files, 0 B
  - **demo** ‚Äî 47 files, 264.6 KB
    - online_inference.py (4.5 KB)
    - pose_extraction.py (3.0 KB)
    - README.md (1.4 KB)
    - **demo/rtmlib-main** ‚Äî 44 files, 255.7 KB
      - .gitignore (1.3 KB)
      - .pre-commit-config.yaml (1.3 KB)
      - body_with_feet_demo.py (1.3 KB)
      - demo.jpg (75.3 KB)
      - hand_demo.py (1.2 KB)
      - LICENSE (11.1 KB)
      - README.md (16.4 KB)
      - requirements.txt (58 B)
      - **demo/rtmlib-main/rtmlib** ‚Äî 32 files, 138.6 KB
        - __init__.py (345 B)
        - version.py (931 B)
        - **demo/rtmlib-main/rtmlib/tools** ‚Äî 21 files, 68.9 KB
          - __init__.py (296 B)
          - base.py (4.5 KB)
          - file.py (5.8 KB)
        - **demo/rtmlib-main/rtmlib/visualization** ‚Äî 9 files, 68.4 KB
          - __init__.py (246 B)
          - draw.py (6.5 KB)
  - **docs** ‚Äî 2 files, 567.7 KB
    - DATASET.md (2.3 KB)
    - framework.png (565.4 KB)
  - **download_scripts** ‚Äî 1 files, 3.6 KB
    - download_CSL_News.py (3.6 KB)
  - **external_metrics** ‚Äî 5 files, 135.9 KB
    - .DS_Store (6.0 KB)
    - __init__.py (0 B)
    - mscoco_rouge.py (2.2 KB)
    - Rouge.py (10.5 KB)
    - sacrebleu.py (117.2 KB)
  - **out** ‚Äî 2 files, 8.6 KB
    - **out/stage1_pretraining** ‚Äî 1 files, 6.0 KB
      - log.txt (6.0 KB)
    - **out/wlbs_stage2_islr** ‚Äî 1 files, 2.6 KB
      - train.log (2.6 KB)
  - **pretrained_weight** ‚Äî 6 files, 2.2 GB
    - **pretrained_weight/mt5-base** ‚Äî 6 files, 2.2 GB
      - config.json (827 B)
      - generation_config.json (142 B)
      - model.safetensors (2.2 GB)
      - special_tokens_map.json (416 B)
      - spiece.model (4.1 MB)
      - tokenizer_config.json (862 B)
  - **script** ‚Äî 6 files, 4.8 KB
    - eval_stage3.sh (709 B)
    - run_stage1.sh (707 B)
    - train_stage1-advanced.sh (1.6 KB)
    - train_stage1.sh (294 B)
    - train_stage2.sh (392 B)
    - train_stage3.sh (1.2 KB)
  - **stgcn_layers** ‚Äî 4 files, 15.6 KB
    - .DS_Store (6.0 KB)
    - __init__.py (69 B)
    - gcn_utils.py (6.0 KB)
    - stgcn_block.py (3.6 KB)
  - **tools** ‚Äî 1 files, 9.7 KB
    - project_map.py (9.7 KB)

## File Previews

### `README.md` (5.4 KB)
```text
<h3 align="center"><a href="" style="color:#9C276A">
Uni-Sign: Toward Unified Sign Language Understanding at Scale</a></h3>
<h5 align="center"> 
If our project helps you, please give us a starüåü on GitHub, that would motivate us a lot!
</h2>
```

### `SLRT_metrics.py` (10.6 KB)
```text
# coding: utf-8
"""
This module holds various MT evaluation metrics.
"""

```

### `config.py` (1.3 KB)
```text
mt5_path = "./pretrained_weight/mt5-base"

# label paths
train_label_paths = {
    "CSL_News": "./data/CSL_News/CSL_News_Labels.json",
```

### `datasets.py` (24.1 KB)
```text
import torch
import utils as utils
import torch.utils.data.dataset as Dataset
from torch.nn.utils.rnn import pad_sequence
from PIL import Image
```

### `deformable_attention_2d.py` (10.4 KB)
```text
# Clone from https://github.com/lucidrains/deformable-attention
import torch
import torch.nn.functional as F
from torch import nn, einsum

```

### `fine_tuning.py` (13.2 KB)
```text
import torch
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import DataLoader
from models import Uni_Sign
import utils as utils
```

### `models.py` (14.8 KB)
```text
from torch import Tensor
import torch
from torch import nn
import torch.utils.checkpoint
import contextlib
```

### `pre_training.py` (10.5 KB)
```text

from pickletools import optimize
import torch
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import DataLoader
```

### `requirements.txt` (446 B)
```text
accelerate==0.29.2
decord==0.6.0
deepspeed==0.16.3
einops==0.6.1
matplotlib==3.4.3
```

### `sitecustomize.py` (252 B)
```text
# Shim to load pickles produced under NumPy 2.x while running NumPy 1.x
import sys, types, numpy as _np
if 'numpy._core' not in sys.modules:
    m = types.ModuleType('numpy._core')
    m.__dict__.update(_np.__dict__)
```

### `utils.py` (21.0 KB)
```text
"""
This file is modified from:
https://github.com/facebookresearch/deit/blob/main/utils.py
"""

```

### `pretrained_weight/mt5-base/config.json` (827 B)
```json
{
  "_name_or_path": "google/mt5-base",
  "architectures": [
    "MT5ForConditionalGeneration"
  ],
```

### `pretrained_weight/mt5-base/generation_config.json` (142 B)
```json
{
  "_from_model_config": true,
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0,
```

### `pretrained_weight/mt5-base/special_tokens_map.json` (416 B)
```json
{
  "eos_token": {
    "content": "</s>",
    "lstrip": false,
    "normalized": false,
```

### `pretrained_weight/mt5-base/tokenizer_config.json` (862 B)
```json
{
  "add_prefix_space": true,
  "added_tokens_decoder": {
    "0": {
      "content": "<pad>",
```

### `external_metrics/Rouge.py` (10.5 KB)
```text
"""ROUGE metric implementation.
Copy from tf_seq2seq/seq2seq/metrics/rouge.py.
This is a modified and slightly extended verison of
https://github.com/miso-belica/sumy/blob/dev/sumy/evaluation/rouge.py.
"""
```

### `external_metrics/__init__.py` (0 B)
```text
[empty]
```

### `external_metrics/mscoco_rouge.py` (2.2 KB)
```text
#!/usr/bin/env python
#
# File Name : mscoco_rouge.py
#
# Description : Computes ROUGE-L metric as described by Lin and Hovey (2004)
```

### `external_metrics/sacrebleu.py` (117.2 KB)
```text
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Copyright 2017--2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
```

### `docs/DATASET.md` (2.3 KB)
```text
### Dataset structure
For simplicity, our datasets are structured in the following way:
```
/Uni-Sign/dataset/
‚îú‚îÄ‚îÄ CSL_News
```

### `data/WLBSL/WLBSL_Labels.csv` (1.4 MB)
```csv
video_path,pose_path,label
/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/rgb_format/abandon_001.mp4,/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/pose_format/abandon_001.pkl,abandon
/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/rgb_format/abashed_001.mp4,/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/pose_format/abashed_001.pkl,abashed
/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/rgb_format/abattoir_001.mp4,/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/pose_format/abattoir_001.pkl,abattoir
/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/rgb_format/abbreviate_001.mp4,/home/danielharding/projects/dev/Uni-Sign/data/WLBSL/pose_format/abbreviate_001.pkl,abbreviate
```

### `data/WLBSL/WLBSL_Labels.json` (771.2 KB)
```json
[
  {
    "video": "abandon_001.mp4",
    "pose": "abandon_001.pkl",
    "text": "abandon"
```

### `data/WLBSL/bsl-text.txt` (9 B)
```text
Text BSL
```

### `data/CSL_News/CSL_News_Labels.csv` (109.2 MB)
```csv
video,pose,text
Common-Concerns_20201113_0-287_14330.mp4,Common-Concerns_20201113_0-287_14330.pkl,Ê¨¢ËøéÊî∂ÁúãÊñ∞ÈóªÈ¢ëÈÅìÔºåÊØèÂ§©ÂçÅÂÖ´ÁÇπ‰∏∫ÊÇ®Áõ¥Êí≠ÁöÑÂÖ±ÂêåÂÖ≥Ê≥®Êµ¶‰∏úÂºÄÂèëÂºÄÊîæ‰∏âÂçÅÂë®Âπ¥Â∫ÜÁ•ùÂ§ß‰ºöÂçÅ‰∫åÂè∑‰∏äÂçàÂú®‰∏äÊµ∑Â∏Ç‰∏æË°å„ÄÇ
Common-Concerns_20201113_1562-2012_239580.mp4,Common-Concerns_20201113_1562-2012_239580.pkl,‰πùÊó∂‰∏âÂçÅÂàÜÔºåÂ§ß‰ºöÂºÄÂßãÔºåÂπ≤Â¶àÂÖ®‰ΩìËµ∑Á´ã„ÄÇ
Common-Concerns_20201113_3237-3612_141834.mp4,Common-Concerns_20201113_3237-3612_141834.pkl,‰ªñÂº∫Ë∞ÉÔºå‰∏âÂçÅÂπ¥ÂâçÔºåÂÖö‰∏≠Â§ÆÂÖ®Èù¢Á†îÂà§ÂõΩÈôÖÂõΩÂÜÖÂ§ß‰∫ãÔºåÁªüÁ≠πÊääÊè°ÊîπÈù©ÂèëÂ±ïÂ§ßÂ±ÄÔºå‰ΩúÂá∫‰∫ÜÂºÄÂèëÂºÄÊîæ„ÄÇ
Common-Concerns_20201113_3562-3812_377955.mp4,Common-Concerns_20201113_3562-3812_377955.pkl,‰∏äÊµ∑Êµ¶‰∏úÁöÑÈáçÂ§ßÂÜ≥Á≠ñÔºåÊéÄÂºÄ‰∫ÜÊàëÂõΩÊîπÈù©ÂºÄÊîæÂêëÁ∫µÊ∑±Êé®ËøõÁöÑÂ¥≠Êñ∞ÁØáÁ´†„ÄÇ
```

### `data/CSL_News/CSL_News_Labels.filtered.skip_pose.json` (137.9 MB)
```json
[
  {
    "video": "Common-Concerns_20201113_0-287_14330.mp4",
    "pose": "Common-Concerns_20201113_0-287_14330.pkl",
    "text": "Ê¨¢ËøéÊî∂ÁúãÊñ∞ÈóªÈ¢ëÈÅìÔºåÊØèÂ§©ÂçÅÂÖ´ÁÇπ‰∏∫ÊÇ®Áõ¥Êí≠ÁöÑÂÖ±ÂêåÂÖ≥Ê≥®Êµ¶‰∏úÂºÄÂèëÂºÄÊîæ‰∏âÂçÅÂë®Âπ¥Â∫ÜÁ•ùÂ§ß‰ºöÂçÅ‰∫åÂè∑‰∏äÂçàÂú®‰∏äÊµ∑Â∏Ç‰∏æË°å„ÄÇ"
```

### `data/CSL_News/CSL_News_Labels.json` (137.9 MB)
```json
[
  {
    "video": "Common-Concerns_20201113_0-287_14330.mp4",
    "pose": "Common-Concerns_20201113_0-287_14330.pkl",
    "text": "Ê¨¢ËøéÊî∂ÁúãÊñ∞ÈóªÈ¢ëÈÅìÔºåÊØèÂ§©ÂçÅÂÖ´ÁÇπ‰∏∫ÊÇ®Áõ¥Êí≠ÁöÑÂÖ±ÂêåÂÖ≥Ê≥®Êµ¶‰∏úÂºÄÂèëÂºÄÊîæ‰∏âÂçÅÂë®Âπ¥Â∫ÜÁ•ùÂ§ß‰ºöÂçÅ‰∫åÂè∑‰∏äÂçàÂú®‰∏äÊµ∑Â∏Ç‰∏æË°å„ÄÇ"
```

### `data/CSL_News/pose_format/check_missing_pose_from_csv.py` (2.7 KB)
```text
#!/usr/bin/env python3
import csv
from pathlib import Path

# --- paths ---
```

### `demo/README.md` (1.4 KB)
```text
## ‚ö†Ô∏è Warning
Due to a busy schedule latelyüò¢, the following demo has not been verified yet.  I wrote it quickly based on logical reasoning to hopefully cover the common needs of many developers/researchersüßë‚Äçüéì. I will check it as soon as possible. If you encounter any problems, feel free to open an issue.

## üõ†Ô∏è Installation
We need to install some package to launch the files in here.
```

### `demo/online_inference.py` (4.5 KB)
```text
import torch
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import DataLoader
from models import Uni_Sign
import utils as utils
```

### `demo/pose_extraction.py` (3.0 KB)
```text
import argparse
import os
import cv2
import glob
import pickle
```

### `demo/rtmlib-main/README.md` (16.4 KB)
```text
# rtmlib

![demo](https://github.com/Tau-J/rtmlib/assets/13503330/b7e8ce8b-3134-43cf-bba6-d81656897289)

rtmlib is a super lightweight library to conduct pose estimation based on [RTMPose](https://github.com/open-mmlab/mmpose/tree/dev-1.x/projects/rtmpose) models **WITHOUT** any dependencies like mmcv, mmpose, mmdet, etc.
```

### `demo/rtmlib-main/body_with_feet_demo.py` (1.3 KB)
```text
import time
import cv2
from rtmlib import BodyWithFeet, PoseTracker, draw_skeleton

device = 'cpu'
```

### `demo/rtmlib-main/hand_demo.py` (1.2 KB)
```text
import time

import cv2

from rtmlib import Hand, PoseTracker, draw_skeleton
```

### `demo/rtmlib-main/requirements.txt` (58 B)
```text
numpy
onnxruntime
opencv-contrib-python
opencv-python
tqdm
```

### `demo/rtmlib-main/rtmo_demo.py` (1.2 KB)
```text
import time

import cv2

from rtmlib import Body, draw_skeleton
```

### `demo/rtmlib-main/setup.py` (4.2 KB)
```text
from setuptools import find_packages, setup


def readme():
    with open('README.md', encoding='utf-8') as f:
```

### `demo/rtmlib-main/webui.py` (2.6 KB)
```text
import gradio as gr
import numpy as np

from rtmlib import Body, Wholebody, draw_skeleton

```

### `demo/rtmlib-main/wholebody_demo.py` (1.2 KB)
```text
import time

import cv2

from rtmlib import PoseTracker, Wholebody, draw_skeleton
```

### `demo/rtmlib-main/rtmlib/__init__.py` (345 B)
```text
from .tools import (RTMO, YOLOX, Body, Hand, PoseTracker, RTMDet, RTMPose,
                    Wholebody, BodyWithFeet, Custom)
from .visualization.draw import draw_bbox, draw_skeleton

__all__ = [
```

### `demo/rtmlib-main/rtmlib/version.py` (931 B)
```text
__version__ = '0.0.13'
short_version = __version__


def parse_version_info(version_str):
```

### `demo/rtmlib-main/rtmlib/visualization/__init__.py` (246 B)
```text
from .draw import draw_bbox, draw_skeleton
from .skeleton import coco17, coco133, hand21, openpose18, openpose134, halpe26

__all__ = [
    'draw_skeleton', 'draw_bbox', 'coco17', 'coco133', 'hand21', 'openpose18',
```

### `demo/rtmlib-main/rtmlib/visualization/draw.py` (6.5 KB)
```text
import math

import cv2
import numpy as np

```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/__init__.py` (267 B)
```text
from .coco17 import coco17
from .coco133 import coco133
from .hand21 import hand21
from .openpose18 import openpose18
from .openpose134 import openpose134
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/coco133.py` (21.6 KB)
```text
coco133 = dict(
    name='coco133',
    keypoint_info={
        0:
        dict(name='nose', id=0, color=[51, 153, 255], swap=''),
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/coco17.py` (5.9 KB)
```text
coco17 = dict(name='coco17',
              keypoint_info={
                  0:
                  dict(name='nose', id=0, color=[51, 153, 255], swap=''),
                  1:
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/halpe26.py` (4.6 KB)
```text
halpe26 = dict(name='halpe26',         
    keypoint_info={
        0: dict(name='nose', id=0, color=[51, 153, 255], type='upper', swap=''),
        1: dict(name='left_eye', id=1, color=[51, 153, 255], type='upper', swap='right_eye'),
        2: dict(name='right_eye', id=2, color=[51, 153, 255], type='upper', swap='left_eye'),
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/hand21.py` (6.0 KB)
```text
hand21 = dict(dataset_name='hand21',
              keypoint_info={
                  0:
                  dict(name='wrist', id=0, color=[255, 255, 255], swap=''),
                  1:
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/openpose134.py` (20.3 KB)
```text
openpose134 = dict(
    name='openpose134',
    keypoint_info={
        0:
        dict(name='nose', id=0, color=[255, 0, 0], swap=''),
```

### `demo/rtmlib-main/rtmlib/visualization/skeleton/openpose18.py` (3.1 KB)
```text
openpose18 = dict(
    name='openpose18',
    keypoint_info={
        0:
        dict(name='nose', id=0, color=[255, 0, 0], swap=''),
```

### `demo/rtmlib-main/rtmlib/tools/__init__.py` (296 B)
```text
from .object_detection import YOLOX, RTMDet
from .pose_estimation import RTMO, RTMPose
from .solution import Body, Hand, PoseTracker, Wholebody, BodyWithFeet, Custom

__all__ = [
```

### `demo/rtmlib-main/rtmlib/tools/base.py` (4.5 KB)
```text
import os
from abc import ABCMeta, abstractmethod
from typing import Any

import cv2
```

### `demo/rtmlib-main/rtmlib/tools/file.py` (5.8 KB)
```text
import hashlib
import os
import re
import sys
import tempfile
```

### `demo/rtmlib-main/rtmlib/tools/pose_estimation/__init__.py` (83 B)
```text
from .rtmo import RTMO
from .rtmpose import RTMPose

__all__ = ['RTMPose', 'RTMO']
```

### `demo/rtmlib-main/rtmlib/tools/pose_estimation/post_processings.py` (2.2 KB)
```text
from typing import Tuple

import numpy as np


```

### `demo/rtmlib-main/rtmlib/tools/pose_estimation/pre_processings.py` (5.3 KB)
```text
from typing import Tuple

import cv2
import numpy as np

```

### `demo/rtmlib-main/rtmlib/tools/pose_estimation/rtmo.py` (4.0 KB)
```text
from typing import List, Tuple

import cv2
import numpy as np

```

### `demo/rtmlib-main/rtmlib/tools/pose_estimation/rtmpose.py` (3.5 KB)
```text
from typing import List, Tuple

import numpy as np

from ..base import BaseTool
```

### `demo/rtmlib-main/rtmlib/tools/solution/__init__.py` (267 B)
```text
from .body import Body
from .hand import Hand
from .pose_tracker import PoseTracker
from .wholebody import Wholebody
from .body_with_feet import BodyWithFeet
```

### `demo/rtmlib-main/rtmlib/tools/solution/body.py` (5.0 KB)
```text
'''
Example:

import cv2

```

### `demo/rtmlib-main/rtmlib/tools/solution/body_with_feet.py` (4.9 KB)
```text
'''
Example:

import cv2
from rtmlib import BodyWithFeet, draw_skeleton
```

### `demo/rtmlib-main/rtmlib/tools/solution/custom.py` (4.2 KB)
```text
'''
Example:

import cv2

```

### `demo/rtmlib-main/rtmlib/tools/solution/hand.py` (2.8 KB)
```text
'''
Example:

import cv2

```

### `demo/rtmlib-main/rtmlib/tools/solution/pose_tracker.py` (8.3 KB)
```text
'''
Example:

import cv2
from functools import partial
```

### `demo/rtmlib-main/rtmlib/tools/solution/wholebody.py` (5.2 KB)
```text
'''
Example:

import cv2

```

### `demo/rtmlib-main/rtmlib/tools/solution/utils/__init__.py` (0 B)
```text
[empty]
```

### `demo/rtmlib-main/rtmlib/tools/solution/utils/types.py` (832 B)
```text
# poted from controlnet repo
from typing import List, NamedTuple, Optional


class Keypoint(NamedTuple):
```

### `demo/rtmlib-main/rtmlib/tools/object_detection/__init__.py` (83 B)
```text
from .rtmdet import RTMDet
from .yolox import YOLOX

__all__ = ['RTMDet', 'YOLOX']
```

### `demo/rtmlib-main/rtmlib/tools/object_detection/post_processings.py` (1.7 KB)
```text
import numpy as np


def nms(boxes, scores, nms_thr):
    """Single class NMS implemented in Numpy."""
```

### `demo/rtmlib-main/rtmlib/tools/object_detection/rtmdet.py` (5.0 KB)
```text
from typing import List, Tuple

import cv2
import numpy as np

```

### `demo/rtmlib-main/rtmlib/tools/object_detection/yolox.py` (5.1 KB)
```text
# Code modified from https://github.com/IDEA-Research/DWPose/blob/opencv_onnx/ControlNet-v1-1-nightly/annotator/dwpose/cv_ox_det.py  # noqa
from typing import List, Tuple

import cv2
import numpy as np
```

### `download_scripts/download_CSL_News.py` (3.6 KB)
```text
# Modified from https://github.com/NJU-PCALab/OpenVid-1M/blob/main/download_scripts/download_OpenVid.py
import os
import subprocess
import argparse

```

### `stgcn_layers/__init__.py` (69 B)
```text
from .gcn_utils import Graph
from .stgcn_block import get_stgcn_chain
```

### `stgcn_layers/gcn_utils.py` (6.0 KB)
```text
import torch
import numpy as np
import torch.nn as nn
import pdb
import math
```

### `stgcn_layers/stgcn_block.py` (3.6 KB)
```text
import torch
import numpy as np
import torch.nn as nn
import pdb
import math
```

### `out/stage1_pretraining/log.txt` (6.0 KB)
```text
{"train_lr": 0.0002993845253182493, "train_loss": 6.785563349599164, "test_loss": 6.148706896551724, "test_bleu1": 12.901555797999029, "test_bleu2": 4.185654343580335, "test_bleu3": 2.0230725999626284, "test_bleu4": 1.1853986319842782, "test_rouge": 13.982612774881856, "epoch": 0, "n_parameters": 58 ‚Ä¶
{"train_lr": 0.00029570729902265216, "train_loss": 6.21276195974207, "test_loss": 5.941271551724138, "test_bleu1": 13.526152319681527, "test_bleu2": 5.908415828256948, "test_bleu3": 3.4084221972124893, "test_bleu4": 2.274847922989226, "test_rouge": 16.068896434631228, "epoch": 1, "n_parameters": 587 ‚Ä¶
{"train_lr": 0.0002884421092059307, "train_loss": 5.917739557917974, "test_loss": 5.65625, "test_bleu1": 22.601668709206542, "test_bleu2": 13.439656594920029, "test_bleu3": 9.232919972286917, "test_bleu4": 6.85038049385354, "test_rouge": 24.108112826705288, "epoch": 2, "n_parameters": 587.747368}
{"train_lr": 0.0002777678572453519, "train_loss": 5.62723655164401, "test_loss": 5.470007183908046, "test_bleu1": 28.4917077510087, "test_bleu2": 18.633522713297126, "test_bleu3": 13.529257476156124, "test_bleu4": 10.40373223447342, "test_rouge": 30.017459700072017, "epoch": 3, "n_parameters": 587.7 ‚Ä¶
{"train_lr": 0.0002639473908269818, "train_loss": 5.442820887068665, "test_loss": 5.3652119252873565, "test_bleu1": 33.460075198406464, "test_bleu2": 22.94460240989155, "test_bleu3": 17.180685393240275, "test_bleu4": 13.498644155085653, "test_rouge": 33.54330188021793, "epoch": 4, "n_parameters": 58 ‚Ä¶
```

### `tools/project_map.py` (9.7 KB)
```text
#!/usr/bin/env python3
"""
Project File System Map + Safe Previews

- Prints a directory tree (bounded depth and entries).
```
