import torch

# --- Target/label normalization shim ---
def _normalize_src_input(src):
    import torch, numpy as _np  # local scope to avoid top-level deps issues
    if isinstance(src, dict):
        return src
    if isinstance(src, (list, tuple)):
        # If any element is a dict, use the first dict (typical for multi-modal collates)
        for item in src:
            if isinstance(item, dict):
                return item
        # Otherwise assume first element is the pose tensor-like payload
        return {'pose': src[0]}
    # If it's a numpy array, convert to tensor; otherwise keep as-is
    try:
        if isinstance(src, _np.ndarray):
            src = torch.from_numpy(src)
    except Exception:
        pass
    return {'pose': src}
# --- end shim ---

from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import DataLoader
from models import Uni_Sign
import utils as utils
# dynamic dataset shim (works for ISLR/WLASL/WLBSL)
try:
    from datasets import S2T_Dataset  # upstream name (SLT)
except Exception:
    import importlib, inspect
    _ds_mod = importlib.import_module('datasets')
    # Try common names in this codebase first, else any *Dataset class
    prefer = ('WLBSL_Dataset','ISLR_Dataset','WLASL_Dataset','S2T_Dataset')
    S2T_Dataset = None
    names = [name for name, obj in inspect.getmembers(_ds_mod, inspect.isclass)]
    for name in prefer:
        if hasattr(_ds_mod, name):
            S2T_Dataset = getattr(_ds_mod, name)
            break
    if S2T_Dataset is None:
        for name, obj in inspect.getmembers(_ds_mod, inspect.isclass):
            if name.endswith('Dataset'):
                S2T_Dataset = obj
                break
    if S2T_Dataset is None:
        raise ImportError(f"No suitable dataset class found in datasets.py; saw classes: {names}")

import os
import time
import argparse, json, datetime
from pathlib import Path
import math
import sys
from timm.optim import create_optimizer
from models import get_requires_grad_dict
from SLRT_metrics import translation_performance, islr_performance, wer_list
from transformers import get_scheduler
from config import *

def main(args):

    utils.init_distributed_mode_ds(args)

    print(args)
    utils.set_seed(args.seed)

    print(f"Creating dataset:")
        
    train_data = S2T_Dataset(path=train_label_paths[args.dataset], 
                             args=args, phase='train')
    print(train_data)
    train_sampler = torch.utils.data.distributed.DistributedSampler(train_data,shuffle=True)
    train_dataloader = DataLoader(train_data,
                                 batch_size=args.batch_size,
                                 num_workers=args.num_workers,
                                 collate_fn=train_data.collate_fn,
                                 sampler=train_sampler,
                                 pin_memory=args.pin_mem,
                                 drop_last=True)

    if hasattr(train_dataloader, "dataset") and len(train_dataloader.dataset) == 0:
        raise RuntimeError(
            "Train dataloader is empty. Check WLBSL split folders under "
            f"{rgb_dirs['WLBSL']} and that your CSV keys match the filenames."
        )
    
    dev_data = S2T_Dataset(path=dev_label_paths[args.dataset],
                           args=args, phase='dev')
    print(dev_data)
    dev_dataloader = None
    if len(dev_data) > 0:
        dev_sampler = torch.utils.data.SequentialSampler(dev_data)
        dev_dataloader = DataLoader(dev_data,
                                    batch_size=args.batch_size,
                                    num_workers=args.num_workers,
                                    collate_fn=dev_data.collate_fn,
                                    sampler=dev_sampler,
                                    pin_memory=args.pin_mem)
    else:
        print("[WARN] dev split is empty â€” skipping validation.")

    test_data = S2T_Dataset(path=test_label_paths[args.dataset],
                            args=args, phase='test')
    print(test_data)
    test_dataloader = None
    if len(test_data) > 0:
        test_sampler = torch.utils.data.SequentialSampler(test_data)
        test_dataloader = DataLoader(test_data,
                                     batch_size=args.batch_size,
                                     num_workers=args.num_workers,
                                     collate_fn=test_data.collate_fn,
                                     sampler=test_sampler,
                                     pin_memory=args.pin_mem)
    else:
        print("[WARN] test split is empty â€” skipping evaluation.")

    print(f"Creating model:")
    model = Uni_Sign(
                args=args
                )
    model.cuda()
    model.train()
    for name, param in model.named_parameters():
        if param.requires_grad:
            param.data = param.data.to(torch.float32)

    if args.require_finetune and args.finetune == '':
        raise RuntimeError("--require_finetune set but no --finetune path provided")

    if args.rgb_support and not getattr(args, 'allow_partial_load', None):
        args.allow_partial_load = 'auto'

    report = Path(args.output_dir) / 'ckpt_load_report.txt'

    init_note = getattr(model, 'rgb_init_note', args.init_rgb_from)

    if args.finetune != '':
        print('***********************************')
        print('Load Checkpoint...')
        print('***********************************')
        ckpt = torch.load(args.finetune, map_location='cpu')
        if isinstance(ckpt, dict) and 'model' in ckpt:
            ckpt = ckpt['model']

        model_state = model.state_dict()
        filtered = {k: v for k, v in ckpt.items() if k in model_state and v.shape == model_state[k].shape}
        missing = [k for k in model_state.keys() if k not in filtered]
        unexpected = [k for k in ckpt.keys() if k not in model_state]

        allow_partial = (args.allow_partial_load == 'true') or (
            args.allow_partial_load == 'auto' and args.rgb_support
        )
        if allow_partial:
            model.load_state_dict(filtered, strict=False)
        else:
            model.load_state_dict(ckpt, strict=True)

        lines = [
            f"file: {args.finetune}",
            f"init_rgb_from: {init_note}",
            f"partial: {'ON' if allow_partial else 'OFF'}",
            f"loaded: {len(filtered)}",
            f"missing: {len(missing)}",
            f"unexpected: {len(unexpected)}",
        ]
        if missing:
            lines.append('missing keys:')
            lines.extend(f'  {k}' for k in missing[:50])
            if len(missing) > 50:
                lines.append(f'  +{len(missing)-50} more')
        if unexpected:
            lines.append('unexpected keys:')
            lines.extend(f'  {k}' for k in unexpected[:50])
            if len(unexpected) > 50:
                lines.append(f'  +{len(unexpected)-50} more')
        report.write_text('\n'.join(lines))
        print(
            f"[ckpt] loaded {len(filtered)} keys; missing {len(missing)}; unexpected {len(unexpected)}. "
            f"partial={'ON' if allow_partial else 'OFF'} (rgb_support={args.rgb_support}). Report: {report}"
        )
    else:
        report.write_text(
            f"file: none\ninit_rgb_from: {init_note}\nloaded: 0\nmissing: 0\nunexpected: 0\n"
        )
    
    model_without_ddp = model
    if args.distributed:
        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)
        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu], find_unused_parameters=True)
        model_without_ddp = model.module
    n_parameters = utils.count_parameters_in_MB(model_without_ddp)
    print(f'number of params: {n_parameters}M')

    optimizer = create_optimizer(args, model_without_ddp)
    lr_scheduler = get_scheduler(
                name='cosine',
                optimizer=optimizer,
                num_warmup_steps=int(args.warmup_epochs * len(train_dataloader)/args.gradient_accumulation_steps),
                num_training_steps=int(args.epochs * len(train_dataloader)/args.gradient_accumulation_steps),
            )
    
    model, optimizer, lr_scheduler = utils.init_deepspeed(args, model, optimizer, lr_scheduler)
    model_without_ddp = model.module.module
    # print(model_without_ddp)
    print(optimizer)

    output_dir = Path(args.output_dir)

    start_time = time.time()
    max_accuracy = 0
    if args.task == "CSLR":
        max_accuracy = 1000
    
    if args.eval:
        if utils.is_main_process():
            if args.task != "ISLR" and dev_dataloader is not None:
                print("ðŸ“„ dev result")
                evaluate(args, dev_dataloader, model, model_without_ddp, phase='dev')
            elif dev_dataloader is None:
                print("[WARN] dev split is empty â€” skipping validation.")
            if test_dataloader is not None:
                print("ðŸ“„ test result")
                evaluate(args, test_dataloader, model, model_without_ddp, phase='test')
            else:
                print("[WARN] test split is empty â€” skipping evaluation.")

        return
    print(f"Start training for {args.epochs} epochs")

    for epoch in range(0, args.epochs):
        if args.distributed:
            train_sampler.set_epoch(epoch)
        
        train_stats = train_one_epoch(args, model, train_dataloader, optimizer, epoch)

        if args.output_dir:
            checkpoint_paths = [output_dir / f'checkpoint_{epoch}.pth']
            for checkpoint_path in checkpoint_paths:
                utils.save_on_master({
                    'model': get_requires_grad_dict(model_without_ddp),
                }, checkpoint_path)

        # single gpu inference
        if utils.is_main_process():
            test_stats = {}
            if dev_dataloader is not None:
                test_stats = evaluate(args, dev_dataloader, model, model_without_ddp, phase='dev')
            else:
                print("[WARN] dev split is empty â€” skipping validation.")
            if test_dataloader is not None:
                evaluate(args, test_dataloader, model, model_without_ddp, phase='test')
            else:
                print("[WARN] test split is empty â€” skipping evaluation.")

            if dev_dataloader is not None:
                if args.task == "SLT":
                    if max_accuracy < test_stats["bleu4"]:
                        max_accuracy = test_stats["bleu4"]
                        if args.output_dir and utils.is_main_process():
                            checkpoint_paths = [output_dir / 'best_checkpoint.pth']
                            for checkpoint_path in checkpoint_paths:
                                utils.save_on_master({
                                    'model': get_requires_grad_dict(model_without_ddp),
                                }, checkpoint_path)

                    print(f"BLEU-4 of the network on the {len(dev_dataloader)} dev videos: {test_stats['bleu4']:.2f}")
                    print(f'Max BLEU-4: {max_accuracy:.2f}%')

                elif args.task == "ISLR":
                    if max_accuracy < test_stats["top1_acc_pi"]:
                        max_accuracy = test_stats["top1_acc_pi"]
                        if args.output_dir and utils.is_main_process():
                            checkpoint_paths = [output_dir / 'best_checkpoint.pth']
                            for checkpoint_path in checkpoint_paths:
                                utils.save_on_master({
                                    'model': get_requires_grad_dict(model_without_ddp),
                                }, checkpoint_path)

                    print(f"PI accuracy of the network on the {len(dev_dataloader)} dev videos: {test_stats['top1_acc_pi']:.2f}")
                    print(f'Max PI accuracy: {max_accuracy:.2f}%')

                elif args.task == "CSLR":
                    if max_accuracy > test_stats["wer"]:
                        max_accuracy = test_stats["wer"]
                        if args.output_dir and utils.is_main_process():
                            checkpoint_paths = [output_dir / 'best_checkpoint.pth']
                            for checkpoint_path in checkpoint_paths:
                                utils.save_on_master({
                                    'model': get_requires_grad_dict(model_without_ddp),
                                }, checkpoint_path)

                    print(f"WER of the network on the {len(dev_dataloader)} dev videos: {test_stats['wer']:.2f}")
                    print(f'Min WER: {max_accuracy:.2f}%')

                log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},
                            **{f'test_{k}': v for k, v in test_stats.items()},
                            'epoch': epoch,
                            'n_parameters': n_parameters}
            else:
                log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},
                            'epoch': epoch,
                            'n_parameters': n_parameters}

        if args.output_dir and utils.is_main_process():
            with (output_dir / "log.txt").open("a") as f:
                f.write(json.dumps(log_stats) + "\n")
        
    total_time = time.time() - start_time
    total_time_str = str(datetime.timedelta(seconds=int(total_time)))
    print('Training time {}'.format(total_time_str))



# --- ISLR-only target normalization ---
def _normalize_islr_target(tgt):
    import numpy as _np
    KEYS = ('label','labels','target','targets','y','cls','class_id','id','tgt')

    # Drill into dicts to find a label field
    if isinstance(tgt, dict):
        for k in KEYS:
            if k in tgt:
                return _normalize_islr_target(tgt[k])
        if len(tgt) == 1:
            return _normalize_islr_target(next(iter(tgt.values())))
        raise ValueError(f"ISLR labels not found in dict keys={list(tgt.keys())}. Expected one of {KEYS}.")

    # Tensor / ndarray -> long vec
    if isinstance(tgt, torch.Tensor):
        return tgt.long().view(-1)
    if 'ndarray' in str(type(tgt)):  # lazy check to avoid importing numpy if not needed
        try:
            return torch.as_tensor(tgt, dtype=torch.long).view(-1)
        except Exception:
            pass

    # Sequence -> list of ints
    if isinstance(tgt, (list, tuple)):
        vals = []
        for e in tgt:
            t = _normalize_islr_target(e)
            if isinstance(t, torch.Tensor):
                vals.extend(t.view(-1).tolist())
            else:
                vals.append(int(t))
        return torch.tensor(vals, dtype=torch.long).view(-1)

    # Strings and scalars -> int tensor of len 1
    if isinstance(tgt, str):
        return torch.tensor([int(tgt)], dtype=torch.long)
    try:
        return torch.tensor([int(tgt)], dtype=torch.long)
    except Exception as e:
        raise TypeError(f"Unsupported ISLR label type: {type(tgt)}") from e




# --- ISLR-only target normalization ---
def _normalize_islr_target(tgt):
    import numpy as _np
    KEYS = ('label','labels','target','targets','y','cls','class_id','id','tgt')

    # Drill into dicts to find a label field
    if isinstance(tgt, dict):
        for k in KEYS:
            if k in tgt:
                return _normalize_islr_target(tgt[k])
        if len(tgt) == 1:
            return _normalize_islr_target(next(iter(tgt.values())))
        raise ValueError(f"ISLR labels not found in dict keys={list(tgt.keys())}. Expected one of {KEYS}.")

    # Tensor / ndarray -> long vec
    if isinstance(tgt, torch.Tensor):
        return tgt.long().view(-1)
    if 'ndarray' in str(type(tgt)):  # lazy check to avoid importing numpy if not needed
        try:
            return torch.as_tensor(tgt, dtype=torch.long).view(-1)
        except Exception:
            pass

    # Sequence -> list of ints
    if isinstance(tgt, (list, tuple)):
        vals = []
        for e in tgt:
            t = _normalize_islr_target(e)
            if isinstance(t, torch.Tensor):
                vals.extend(t.view(-1).tolist())
            else:
                vals.append(int(t))
        return torch.tensor(vals, dtype=torch.long).view(-1)

    # Strings and scalars -> int tensor of len 1
    if isinstance(tgt, str):
        return torch.tensor([int(tgt)], dtype=torch.long)
    try:
        return torch.tensor([int(tgt)], dtype=torch.long)
    except Exception as e:
        raise TypeError(f"Unsupported ISLR label type: {type(tgt)}") from e




# --- ISLR-only target normalization ---
def _normalize_islr_target(tgt):
    import numpy as _np
    KEYS = ('label','labels','target','targets','y','cls','class_id','id','tgt')

    # Drill into dicts to find a label field
    if isinstance(tgt, dict):
        for k in KEYS:
            if k in tgt:
                return _normalize_islr_target(tgt[k])
        if len(tgt) == 1:
            return _normalize_islr_target(next(iter(tgt.values())))
        raise ValueError(f"ISLR labels not found in dict keys={list(tgt.keys())}. Expected one of {KEYS}.")

    # Tensor / ndarray -> long vec
    if isinstance(tgt, torch.Tensor):
        return tgt.long().view(-1)
    if 'ndarray' in str(type(tgt)):  # lazy check to avoid importing numpy if not needed
        try:
            return torch.as_tensor(tgt, dtype=torch.long).view(-1)
        except Exception:
            pass

    # Sequence -> list of ints
    if isinstance(tgt, (list, tuple)):
        vals = []
        for e in tgt:
            t = _normalize_islr_target(e)
            if isinstance(t, torch.Tensor):
                vals.extend(t.view(-1).tolist())
            else:
                vals.append(int(t))
        return torch.tensor(vals, dtype=torch.long).view(-1)

    # Strings and scalars -> int tensor of len 1
    if isinstance(tgt, str):
        return torch.tensor([int(tgt)], dtype=torch.long)
    try:
        return torch.tensor([int(tgt)], dtype=torch.long)
    except Exception as e:
        raise TypeError(f"Unsupported ISLR label type: {type(tgt)}") from e


def train_one_epoch(args, model, data_loader, optimizer, epoch):
    model.train()

    metric_logger = utils.MetricLogger(delimiter="  ")
    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))
    header = 'Epoch: [{}/{}]'.format(epoch, args.epochs)
    print_freq = 10
    optimizer.zero_grad()

    use_bf16 = hasattr(model, "bfloat16_enabled") and model.bfloat16_enabled()
    target_dtype = torch.bfloat16 if use_bf16 else None

    for step, batch in enumerate(metric_logger.log_every(data_loader, print_freq, header)):
        # Unpack (src, tgt [, meta]) or dict
        if isinstance(batch, (list, tuple)):
            if len(batch) >= 3:
                src_input, tgt_input, meta = batch[:3]
            elif len(batch) == 2:
                src_input, tgt_input = batch
                meta = None
            else:
                raise ValueError(f"Unexpected batch length: {len(batch)}")
        elif isinstance(batch, dict):
            src_input = batch.get('src_input') or batch.get('src')
            tgt_input = batch.get('tgt_input') or batch.get('tgt') or batch.get('label')
            meta = batch.get('meta', None)
        else:
            raise ValueError(f"Unexpected batch type: {type(batch)}")

        # Normalize/move src to GPU
        src_input = _normalize_src_input(src_input)
        for k, v in list(src_input.items()):
            if isinstance(v, torch.Tensor):
                if target_dtype is not None and v.dtype.is_floating_point:
                    v = v.to(target_dtype)
                src_input[k] = v.cuda(non_blocking=True)

        # Normalize tgt per task
        if args.task == "ISLR":
            tgt_input = _normalize_islr_target(tgt_input).cuda(non_blocking=True)
        else:
            # SLT / CSLR keep dict-style targets
            if not isinstance(tgt_input, dict):
                tgt_input = {'gt_sentence': tgt_input}
            if args.task == "CSLR" and 'gt_sentence' not in tgt_input and 'gt_gloss' in tgt_input:
                tgt_input['gt_sentence'] = tgt_input['gt_gloss']

        # Forward/backward
        out = model(src_input, tgt_input)
        total_loss = out['loss']
        model.backward(total_loss)
        model.step()

        loss_value = total_loss.item()
        if not math.isfinite(loss_value):
            print(f"Loss is {loss_value}, stopping training")
            sys.exit(1)

        metric_logger.update(loss=loss_value)
        metric_logger.update(lr=optimizer.param_groups[0]["lr"])

    metric_logger.synchronize_between_processes()
    print("Averaged stats:", metric_logger)
    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}


def evaluate(args, data_loader, model, model_without_ddp, phase):
    model.eval()

    metric_logger = utils.MetricLogger(delimiter="  ")
    header = 'Test:'
    print_freq = 10

    use_bf16 = hasattr(model, "bfloat16_enabled") and model.bfloat16_enabled()
    target_dtype = torch.bfloat16 if use_bf16 else None

    with torch.no_grad():
        tgt_pres = []  # predicted strings
        tgt_refs = []  # reference strings

        for step, batch in enumerate(metric_logger.log_every(data_loader, print_freq, header)):
            # Unpack
            if isinstance(batch, (list, tuple)):
                if len(batch) >= 3:
                    src_input, tgt_input, meta = batch[:3]
                elif len(batch) == 2:
                    src_input, tgt_input = batch
                    meta = None
                else:
                    raise ValueError(f"Unexpected batch length: {len(batch)}")
            elif isinstance(batch, dict):
                src_input = batch.get('src_input') or batch.get('src')
                tgt_input = batch.get('tgt_input') or batch.get('tgt') or batch.get('label')
                meta = batch.get('meta', None)
            else:
                raise ValueError(f"Unexpected batch type: {type(batch)}")

            # Normalize/move src
            src_input = _normalize_src_input(src_input)
            for k, v in list(src_input.items()):
                if isinstance(v, torch.Tensor):
                    if target_dtype is not None and v.dtype.is_floating_point:
                        v = v.to(target_dtype)
                    src_input[k] = v.cuda(non_blocking=True)

            # Ensure dict-style targets for generation/reference strings
            if not isinstance(tgt_input, dict):
                tgt_input = {'gt_sentence': tgt_input}
            if args.task == "CSLR" and 'gt_sentence' not in tgt_input and 'gt_gloss' in tgt_input:
                tgt_input['gt_sentence'] = tgt_input['gt_gloss']

            # Forward (no backward)
            out = model(src_input, tgt_input)
            total_loss = out['loss']
            metric_logger.update(loss=total_loss.item())

            # Generate token ids and decode
            gen_ids = model_without_ddp.generate(out, max_new_tokens=100, num_beams=4)
            # convert to list-of-ids for tokenizer
            pred_id_lists = []
            for g in gen_ids:
                if isinstance(g, torch.Tensor):
                    pred_id_lists.append(g.detach().cpu().tolist())
                else:
                    pred_id_lists.append(list(g))
            tokenizer = model_without_ddp.mt5_tokenizer
            pred_texts = tokenizer.batch_decode(pred_id_lists, skip_special_tokens=True)

            # refs
            refs = tgt_input.get('gt_sentence')
            if isinstance(refs, (list, tuple)):
                ref_texts = [str(r) for r in refs]
            else:
                ref_texts = [str(refs)] * len(pred_texts)

            # collect
            tgt_pres.extend(pred_texts)
            tgt_refs.extend(ref_texts)

    # Post-process for CSL_Daily SLT quirk
    if args.dataset == 'CSL_Daily' and args.task == "SLT":
        tgt_pres = [' '.join(list(r.replace(" ",'').replace("\n",''))) for r in tgt_pres]
        tgt_refs = [' '.join(list(r.replace("ï¼Œ", ',').replace("ï¼Ÿ","?").replace(" ",''))) for r in tgt_refs]

    # Metrics
    if args.task == "SLT":
        bleu_dict, rouge_score = translation_performance(tgt_refs, tgt_pres)
        for k, v in bleu_dict.items():
            metric_logger.meters[k].update(v)
        metric_logger.meters['rouge'].update(rouge_score)

    elif args.task == "ISLR":
        top1_acc_pi, top1_acc_pc = islr_performance(tgt_refs, tgt_pres)
        metric_logger.meters['top1_acc_pi'].update(top1_acc_pi)
        metric_logger.meters['top1_acc_pc'].update(top1_acc_pc)

    elif args.task == "CSLR":
        wer_results = wer_list(hypotheses=tgt_pres, references=tgt_refs)
        for k, v in wer_results.items():
            metric_logger.meters[k].update(v)

    # Optionally dump preds/refs only when evaluating (args.eval on a single process)
    if utils.is_main_process() and utils.get_world_size() == 1 and args.eval:
        out_dir = Path(args.output_dir)
        (out_dir / f"{phase}_tmp_pres.txt").write_text("\n".join(map(str, tgt_pres)) + "\n")
        (out_dir / f"{phase}_tmp_refs.txt").write_text("\n".join(map(str, tgt_refs)) + "\n")

    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}

